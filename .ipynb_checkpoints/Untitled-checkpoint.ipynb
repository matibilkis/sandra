{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "prime-assessment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "sorted-colonial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MetaModel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-291-1565ea7d230c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnetworks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMetaModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MetaModel'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "from networks import Encoder, Decoder, MetaModel\n",
    "import numpy as np\n",
    "import ast\n",
    "from sindy import SINDy\n",
    "\n",
    "\n",
    "\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fresh-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform((1,128))\n",
    "x_dot = tf.random.uniform((1,128))\n",
    "\n",
    "encoder = Encoder()\n",
    "encoder(x)\n",
    "\n",
    "sindy = SINDICALISTA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "freelance-thunder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "corresponding-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [encoder, decoder, sindy]\n",
    "kafka = ModelOrganizer(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "invalid-latter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "external-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "Nsteps = 1\n",
    "x = tf.random.uniform((bs,Nsteps,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sweet-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_dot = tf.random.uniform((2,bs,Nsteps,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "periodic-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINDy(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SINDICALISTA,self).__init__()\n",
    "        self.coeffs = tf.ones((3,27))\n",
    "\n",
    "    def theta(self,z):\n",
    "        th = []\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                for k in range(3):\n",
    "                    th.append(tf.reduce_prod(tf.stack([tf.pow(z[:,:,0], i),tf.pow(z[:,:,1], j),tf.pow(z[:,:,2], k)]), axis=0))\n",
    "        return tf.transpose(tf.stack(th,axis=0), perm=[1,2,0]) #returns [Nbatch, Ntimestep, 27]\n",
    "\n",
    "    def __call__(self, phi_of_ex):\n",
    "        thetas = self.theta(phi_of_ex)\n",
    "        zdot_sindy = tf.einsum('bte,ze->btz',thetas, self.coeffs)\n",
    "        return zdot_sindy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "spare-assembly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7efcdde83d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function pfor.<locals>.f at 0x7efcdde83d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-somalia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-valve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-thomson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-modem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(models, data):\n",
    "    x, x_dot = data\n",
    "    encoder, decoder, sindy = models\n",
    "    ### LOSS 0 and 1 ###\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(encoder.trainable_variables)\n",
    "        tape.watch(decoder.trainable_variables)\n",
    "        tape.watch(x)\n",
    "        tape.watch(tf.convert_to_tensor(sindy.coeffs))\n",
    "\n",
    "        z = encoder(x)\n",
    "        tape.watch(z)\n",
    "        x_quasi = decoder(z)\n",
    "\n",
    "        loss0 = tf.keras.losses.MSE(x,x_quasi)\n",
    "        zdot_sindy = sindy(tf.transpose(z))\n",
    "\n",
    "        with tape.stop_recording():\n",
    "            dpsi_dz = tf.squeeze(tape.jacobian(x_quasi, z))\n",
    "        xdot_pred = tf.matmul(zdot_sindy,dpsi_dz, transpose_b=True)\n",
    "        loss1 = tf.keras.losses.MSE(x_dot,xdot_pred)\n",
    "\n",
    "        ### LOSS 2 and 4 ###\n",
    "        with tape.stop_recording():\n",
    "            dphi_dx = tf.squeeze(tape.jacobian(z,x))\n",
    "        #tf.einsum('ij,j->i', dphi_dx, tf.squeeze(x_dot))\n",
    "        zdot_pred = tf.matmul(x_dot, dphi_dx, transpose_b=True)\n",
    "        encoder_output = np.squeeze(encoder(x))\n",
    "        loss2 = tf.cast(tf.keras.losses.MSE(zdot_pred, zdot_sindy),tf.float32)\n",
    "\n",
    "        loss3 = tf.expand_dims(tf.einsum('ij->',tf.math.abs(sindy.coeffs)),axis=0)\n",
    "        total_loss = loss0 + loss1 + loss2 + loss3 \n",
    "\n",
    "    grads_encoder = tape.gradient(total_loss, models[0].trainable_variables)\n",
    "    grads_decoder = tape.gradient(total_loss, models[1].trainable_variables)\n",
    "    grads_sindy_coeffs = tape.gradient(total_loss, models[2])\n",
    "\n",
    "    gradients = [grads_encoder, grads_decoder, grads_sindy_coeffs]\n",
    "    for model, gradient in zip(models, gradients):\n",
    "        model.optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "    losses = tf.stack([loss0,loss1,loss2,loss3,loss4])\n",
    "    return total_loss, losses\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
